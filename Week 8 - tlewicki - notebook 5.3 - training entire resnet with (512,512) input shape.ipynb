{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stage_2_sample_submission.csv  stage_2_test  stage_2_train  stage_2_train.csv\r\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "DATA_DIR = '/data/cmpe257-02-fa2019/team-1-meerkats/rsna-intracranial-hemorrhage-detection/'\n",
    "MODEL_NAME = 'frozen_VGG_dense_head_new_windowing'\n",
    "TIMESTAMP_BEGIN = int(time.time())\n",
    "!ls $DATA_DIR\n",
    "INPUT_SHAPE = (512, 512, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# dcm processing\n",
    "\n",
    "def correct_dcm(dcm):\n",
    "    x = dcm.pixel_array + 1000\n",
    "    px_mode = 4096\n",
    "    x[x>=px_mode] = x[x>=px_mode] - px_mode\n",
    "    dcm.PixelData = x.tobytes()\n",
    "    dcm.RescaleIntercept = -1000\n",
    "\n",
    "def window_image(dcm, window_center, window_width):\n",
    "    \n",
    "    #handle the 12 bit values\n",
    "    if (dcm.BitsStored == 12) and (dcm.PixelRepresentation == 0) and (int(dcm.RescaleIntercept) > -100):\n",
    "        correct_dcm(dcm)\n",
    "    \n",
    "    img = dcm.pixel_array * dcm.RescaleSlope + dcm.RescaleIntercept\n",
    "    img_min = window_center - window_width // 2\n",
    "    img_max = window_center + window_width // 2\n",
    "    img = np.clip(img, img_min, img_max)\n",
    "\n",
    "    return img\n",
    "\n",
    "def window_and_scale_brain_subdural_soft(dcm):\n",
    "    \n",
    "    #window images\n",
    "    brain_img = window_image(dcm, 40, 80)\n",
    "    subdural_img = window_image(dcm, 80, 200)\n",
    "    #soft_img = window_image(dcm, 40, 380)\n",
    "    bone_img = window_image(dcm, 600, 2800)\n",
    "    \n",
    "    #scale images (0-1)\n",
    "    brain_img = (brain_img - 0) / 80\n",
    "    subdural_img = (subdural_img + 20) / 200\n",
    "    bone_img = (bone_img + 800) / 2800\n",
    "    \n",
    "    # combine channels\n",
    "    return np.array([brain_img, subdural_img, bone_img]).transpose(1,2,0)\n",
    "\n",
    "def old_window_and_scale(dcm):\n",
    "    brain_img = window_image(dcm, 40, 80)\n",
    "    subdural_img = window_image(dcm, 80, 200)\n",
    "    soft_img = window_image(dcm, 40, 380)\n",
    "    \n",
    "    brain_img = (brain_img - 0) / 80\n",
    "    subdural_img = (subdural_img - (-20)) / 200\n",
    "    soft_img = (soft_img - (-150)) / 380\n",
    "    bsb_img = np.array([brain_img, subdural_img, soft_img]).transpose(1,2,0)\n",
    "\n",
    "    return bsb_img\n",
    "\n",
    "\n",
    "def read_trainset(filename=DATA_DIR+\"stage_2_train.csv\"):\n",
    "    df = pd.read_csv(filename)\n",
    "    df[\"Image\"] = df[\"ID\"].str.slice(stop=12)\n",
    "    df[\"Diagnosis\"] = df[\"ID\"].str.slice(start=13)\n",
    "    \n",
    "    duplicates_to_remove = [\n",
    "        56346,56347,56348,56349,\n",
    "        56350,56351,1171830,1171831,\n",
    "        1171832,1171833,1171834,1171835,\n",
    "        3705312,3705313,3705314,3705315,\n",
    "        3705316,3705317,3842478,3842479,\n",
    "        3842480,3842481,3842482,3842483\n",
    "    ]\n",
    "    \n",
    "    df = df.drop(index=duplicates_to_remove)\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    df = df.loc[:, [\"Label\", \"Diagnosis\", \"Image\"]]\n",
    "    df = df.set_index(['Image', 'Diagnosis']).unstack(level=-1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import cv2\n",
    "from math import ceil\n",
    "import numpy as np\n",
    "import pydicom\n",
    "\n",
    "np.random.seed(2557)\n",
    "\n",
    "def _read(path, desired_size):\n",
    "    \"\"\"Will be used in DataGenerator\"\"\"\n",
    "    \n",
    "    dcm = pydicom.dcmread(path)\n",
    "    \n",
    "    try:\n",
    "        img = window_and_scale_brain_subdural_soft(dcm)\n",
    "        img = cv2.resize(img, desired_size[:2], interpolation=cv2.INTER_LINEAR)\n",
    "        \n",
    "    # Some dcms seem to be corrupted\n",
    "    except ValueError:\n",
    "        print('Error while parsing {}'.format(path))\n",
    "        img = np.ones(desired_size)\n",
    "    \n",
    "    return img\n",
    "\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "\n",
    "    def __init__(self, img_dir, image_IDs, labels_df, batch_size, img_size):\n",
    "\n",
    "        self.image_IDs = image_IDs\n",
    "        self.labels_df = labels_df\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "        self.img_dir = img_dir\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(ceil(len(self.image_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        batch_ids = self.image_IDs[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        \n",
    "        X = np.empty((self.batch_size, *self.img_size))\n",
    "        Y = np.empty((self.batch_size, 6))\n",
    "        \n",
    "        for i, ID in enumerate(batch_ids):\n",
    "            X[i,] = _read(self.img_dir+ID+\".dcm\", self.img_size)\n",
    "            Y[i,] = self.labels_df.loc[ID].values\n",
    "        \n",
    "        return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit \n",
    "\n",
    "train_df = read_trainset()\n",
    "\n",
    "# k-fold splitting\n",
    "ss = ShuffleSplit(n_splits=10, test_size=0.1, random_state=257).split(train_df.index)\n",
    "# get indeces for one split\n",
    "train_idx, valid_idx = next(ss)\n",
    "train_df_kfold = train_df.iloc[train_idx]\n",
    "valid_df_kfold = train_df.iloc[valid_idx]\n",
    "\n",
    "\n",
    "traingen = DataGenerator(img_dir=DATA_DIR+'stage_2_train/',\n",
    "                         image_IDs=train_df_kfold.index[:10000], #MAGIC\n",
    "                         labels_df=train_df_kfold[:10000], #MAGIC\n",
    "                         batch_size=8,\n",
    "                         img_size=INPUT_SHAPE)\n",
    "\n",
    "validgen = DataGenerator(img_dir=DATA_DIR+'stage_2_train/',\n",
    "                         image_IDs=valid_df_kfold.index[:1000], #MAGIC\n",
    "                         labels_df=valid_df_kfold[:1000], #MAGIC\n",
    "                         batch_size=8,\n",
    "                         img_size=INPUT_SHAPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom loss function\n",
    "from keras import backend as K\n",
    "\n",
    "def weighted_log_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Can be used as the loss function in model.compile()\n",
    "    ---------------------------------------------------\n",
    "    \"\"\"\n",
    "    \n",
    "    class_weights = np.array([1., 1., 1., 1., 1., 1.])\n",
    "    \n",
    "    eps = K.epsilon()\n",
    "    \n",
    "    y_pred = K.clip(y_pred, eps, 1.0-eps)\n",
    "\n",
    "    out = -(         y_true  * K.log(      y_pred) * class_weights\n",
    "            + (1.0 - y_true) * K.log(1.0 - y_pred) * class_weights)\n",
    "    \n",
    "    return K.mean(out, axis=-1)\n",
    "\n",
    "# custom performance metric\n",
    "def correct_diagnoses(y_true, y_pred):\n",
    "    THRESHOLD = 0.5\n",
    "    p_thr = K.greater(y_pred, THRESHOLD)\n",
    "    y_true = K.cast(y_true, dtype='bool')\n",
    "    \n",
    "    equals_t = K.equal(p_thr, y_true)\n",
    "    correct_rows = K.all(equals_t, axis=1)\n",
    "    correct_rows_int = K.cast(correct_rows, dtype='int32')\n",
    "    \n",
    "    return K.sum(correct_rows_int)/K.shape(correct_rows_int)[0]\n",
    "\n",
    "def correct_positive_diagnoses(y_true, y_pred):\n",
    "    THRESHOLD = 0.5\n",
    "    p_thr = K.greater(y_pred, THRESHOLD)\n",
    "    y_true = K.cast(y_true, dtype='bool')\n",
    "    \n",
    "    pos_mask = K.any(y_true, axis=1) #patients with positive diagnoses\n",
    "    p_thr = p_thr[pos_mask]\n",
    "    y_true = y_true[pos_mask]\n",
    "    \n",
    "    equals_t = K.equal(p_thr, y_true)\n",
    "    correct_rows = K.all(equals_t, axis=1)\n",
    "    correct_rows_float = K.cast(correct_rows, dtype='float32')\n",
    "    \n",
    "    return K.sum(correct_rows_float)/(K.cast(K.shape(correct_rows_float)[0], dtype='float32')+K.epsilon())\n",
    "\n",
    "def np_cpd(y_true, pred, thr=0.5): #numpy implementation of correct positive diagnoses\n",
    "    p_thr = pred > thr\n",
    "\n",
    "    pos_mask = np.any(y_true, axis=1)\n",
    "\n",
    "    p_thr = p_thr[pos_mask]\n",
    "    y_true = y_true[pos_mask]\n",
    "\n",
    "    p_correct = np.all(p_thr[:len(y_true)] == y_true[:len(p_thr)], axis=1)\n",
    "\n",
    "    return np.sum(p_correct)/(len(p_thr)+1e-15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/013855803/anaconda3/envs/brainenv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/013855803/anaconda3/envs/brainenv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/013855803/anaconda3/envs/brainenv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/013855803/anaconda3/envs/brainenv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/013855803/anaconda3/envs/brainenv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/013855803/anaconda3/envs/brainenv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/013855803/anaconda3/envs/brainenv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/013855803/anaconda3/envs/brainenv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/013855803/anaconda3/envs/brainenv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/013855803/anaconda3/envs/brainenv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/013855803/anaconda3/envs/brainenv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/013855803/anaconda3/envs/brainenv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/013855803/anaconda3/envs/brainenv/lib/python3.7/site-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/013855803/anaconda3/envs/brainenv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/013855803/anaconda3/envs/brainenv/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/013855803/anaconda3/envs/brainenv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/013855803/anaconda3/envs/brainenv/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Model)             (None, 16, 16, 2048)      23587712  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 524288)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               134217984 \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 157,807,238\n",
      "Trainable params: 157,754,118\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "#from keras.applications.vgg16 import VGG16\n",
    "from keras.applications import ResNet50\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "\n",
    "#conv_base = VGG16(weights=None, input_shape=INPUT_SHAPE ,include_top=False)\n",
    "conv_base = ResNet50(include_top=False, weights='imagenet', input_shape=INPUT_SHAPE)\n",
    "#conv_base.load_weights('vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5') #doesn't work otherwise without internet access\n",
    "\n",
    "conv_base.trainable = True\n",
    "model = keras.models.Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dense(6, activation='sigmoid'))\n",
    "model.name = MODEL_NAME\n",
    "model.compile(\n",
    "    #loss=weighted_log_loss, #custom loss\n",
    "    loss='binary_crossentropy',\n",
    "    #loss='categorical_crossentropy', # mutually exclusive\n",
    "    optimizer=keras.optimizers.Adam(lr=1e-5),\n",
    "    metrics=[correct_positive_diagnoses])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = keras.callbacks.ModelCheckpoint(filepath='weights/'+MODEL_NAME+'-epoch={epoch:02d}-valid-loss={val_loss:.2f}.hdf5', monitor='loss', verbose=True, save_best_only=False, save_weights_only=False)\n",
    "tb = keras.callbacks.TensorBoard(log_dir='./Graph', histogram_freq=0,  \n",
    "          write_graph=True, write_images=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.1782 - correct_positive_diagnoses: 0.0188Epoch 1/20\n",
      "1250/1250 [==============================] - 554s 444ms/step - loss: 0.1780 - correct_positive_diagnoses: 0.0188 - val_loss: 0.1362 - val_correct_positive_diagnoses: 0.0640\n",
      "\n",
      "Epoch 00001: saving model to weights/frozen_VGG_dense_head_new_windowing-epoch=01-valid-loss=0.14.hdf5\n",
      "Epoch 2/20\n",
      "1250/1250 [==============================] - 533s 427ms/step - loss: 0.0633 - correct_positive_diagnoses: 0.2873 - val_loss: 0.1382 - val_correct_positive_diagnoses: 0.0587\n",
      "\n",
      "Epoch 00002: saving model to weights/frozen_VGG_dense_head_new_windowing-epoch=02-valid-loss=0.14.hdf5\n",
      "Epoch 3/20\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.0173 - correct_positive_diagnoses: 0.5835\n",
      "Epoch 00002: saving model to weights/frozen_VGG_dense_head_new_windowing-epoch=02-valid-loss=0.14.hdf5\n",
      "1250/1250 [==============================] - 532s 426ms/step - loss: 0.0173 - correct_positive_diagnoses: 0.5839 - val_loss: 0.1880 - val_correct_positive_diagnoses: 0.0816\n",
      "\n",
      "Epoch 00003: saving model to weights/frozen_VGG_dense_head_new_windowing-epoch=03-valid-loss=0.19.hdf5\n",
      "Epoch 4/20\n",
      "1250/1250 [==============================] - 533s 426ms/step - loss: 0.0074 - correct_positive_diagnoses: 0.6542 - val_loss: 0.2009 - val_correct_positive_diagnoses: 0.0840\n",
      "\n",
      "Epoch 00004: saving model to weights/frozen_VGG_dense_head_new_windowing-epoch=04-valid-loss=0.20.hdf5\n",
      "Epoch 5/20\n",
      "1250/1250 [==============================] - 535s 428ms/step - loss: 0.0073 - correct_positive_diagnoses: 0.6578 - val_loss: 0.2350 - val_correct_positive_diagnoses: 0.0760\n",
      "\n",
      "Epoch 00005: saving model to weights/frozen_VGG_dense_head_new_windowing-epoch=05-valid-loss=0.24.hdf5\n",
      "Epoch 6/20\n",
      "1250/1250 [==============================] - 539s 431ms/step - loss: 0.0065 - correct_positive_diagnoses: 0.6579 - val_loss: 0.2515 - val_correct_positive_diagnoses: 0.1096\n",
      "\n",
      "Epoch 00006: saving model to weights/frozen_VGG_dense_head_new_windowing-epoch=06-valid-loss=0.25.hdf5\n",
      "Epoch 7/20\n",
      "1250/1250 [==============================] - 544s 435ms/step - loss: 0.0032 - correct_positive_diagnoses: 0.6791 - val_loss: 0.2566 - val_correct_positive_diagnoses: 0.0720\n",
      "\n",
      "Epoch 00007: saving model to weights/frozen_VGG_dense_head_new_windowing-epoch=07-valid-loss=0.26.hdf5\n",
      "Epoch 8/20\n",
      "1250/1250 [==============================] - 541s 432ms/step - loss: 0.0061 - correct_positive_diagnoses: 0.6690 - val_loss: 0.2176 - val_correct_positive_diagnoses: 0.0880\n",
      "\n",
      "Epoch 00008: saving model to weights/frozen_VGG_dense_head_new_windowing-epoch=08-valid-loss=0.22.hdf5\n",
      "Epoch 9/20\n",
      "1250/1250 [==============================] - 533s 426ms/step - loss: 0.0018 - correct_positive_diagnoses: 0.6925 - val_loss: 0.3224 - val_correct_positive_diagnoses: 0.0860\n",
      "\n",
      "Epoch 00008: saving model to weights/frozen_VGG_dense_head_new_windowing-epoch=08-valid-loss=0.22.hdf5\n",
      "\n",
      "Epoch 00009: saving model to weights/frozen_VGG_dense_head_new_windowing-epoch=09-valid-loss=0.32.hdf5\n",
      "Epoch 10/20\n",
      "1250/1250 [==============================] - 530s 424ms/step - loss: 0.0034 - correct_positive_diagnoses: 0.6810 - val_loss: 0.2452 - val_correct_positive_diagnoses: 0.1167\n",
      "\n",
      "Epoch 00010: saving model to weights/frozen_VGG_dense_head_new_windowing-epoch=10-valid-loss=0.25.hdf5\n",
      "Epoch 11/20\n",
      "1250/1250 [==============================] - 533s 426ms/step - loss: 0.0039 - correct_positive_diagnoses: 0.6783 - val_loss: 0.2702 - val_correct_positive_diagnoses: 0.0907\n",
      "\n",
      "Epoch 00011: saving model to weights/frozen_VGG_dense_head_new_windowing-epoch=11-valid-loss=0.27.hdf5\n",
      "\n",
      "Epoch 00010: saving model to weights/frozen_VGG_dense_head_new_windowing-epoch=10-valid-loss=0.25.hdf5\n",
      "Epoch 12/20\n",
      "1250/1250 [==============================] - 532s 426ms/step - loss: 0.0027 - correct_positive_diagnoses: 0.6862 - val_loss: 0.3010 - val_correct_positive_diagnoses: 0.0760\n",
      "\n",
      "Epoch 00012: saving model to weights/frozen_VGG_dense_head_new_windowing-epoch=12-valid-loss=0.30.hdf5\n",
      "Epoch 13/20\n",
      "1250/1250 [==============================] - 532s 426ms/step - loss: 0.0028 - correct_positive_diagnoses: 0.6851 - val_loss: 0.2405 - val_correct_positive_diagnoses: 0.1007\n",
      "\n",
      "Epoch 00013: saving model to weights/frozen_VGG_dense_head_new_windowing-epoch=13-valid-loss=0.24.hdf5\n",
      "Epoch 14/20\n",
      "1250/1250 [==============================] - 532s 426ms/step - loss: 0.0024 - correct_positive_diagnoses: 0.6871 - val_loss: 0.2685 - val_correct_positive_diagnoses: 0.0773\n",
      "\n",
      "Epoch 00014: saving model to weights/frozen_VGG_dense_head_new_windowing-epoch=14-valid-loss=0.27.hdf5\n",
      "Epoch 15/20\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.0033 - correct_positive_diagnoses: 0.6887\n",
      "Epoch 00014: saving model to weights/frozen_VGG_dense_head_new_windowing-epoch=14-valid-loss=0.27.hdf5\n",
      "1250/1250 [==============================] - 546s 437ms/step - loss: 0.0033 - correct_positive_diagnoses: 0.6889 - val_loss: 0.2580 - val_correct_positive_diagnoses: 0.0660\n",
      "\n",
      "Epoch 00015: saving model to weights/frozen_VGG_dense_head_new_windowing-epoch=15-valid-loss=0.26.hdf5\n",
      "Epoch 16/20\n",
      "1250/1250 [==============================] - 543s 434ms/step - loss: 3.6346e-04 - correct_positive_diagnoses: 0.6980 - val_loss: 0.2814 - val_correct_positive_diagnoses: 0.0880\n",
      "\n",
      "Epoch 00016: saving model to weights/frozen_VGG_dense_head_new_windowing-epoch=16-valid-loss=0.28.hdf5\n",
      "Epoch 17/20\n",
      "1250/1250 [==============================] - 535s 428ms/step - loss: 2.1548e-04 - correct_positive_diagnoses: 0.6991 - val_loss: 0.2951 - val_correct_positive_diagnoses: 0.0567\n",
      "\n",
      "Epoch 00017: saving model to weights/frozen_VGG_dense_head_new_windowing-epoch=17-valid-loss=0.30.hdf5\n",
      "Epoch 18/20\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 3.6668e-05 - correct_positive_diagnoses: 0.7006\n",
      "Epoch 00017: saving model to weights/frozen_VGG_dense_head_new_windowing-epoch=17-valid-loss=0.30.hdf5\n",
      "1250/1250 [==============================] - 536s 428ms/step - loss: 3.6642e-05 - correct_positive_diagnoses: 0.7008 - val_loss: 0.2949 - val_correct_positive_diagnoses: 0.0640\n",
      "\n",
      "Epoch 00018: saving model to weights/frozen_VGG_dense_head_new_windowing-epoch=18-valid-loss=0.29.hdf5\n",
      "Epoch 19/20\n",
      "1250/1250 [==============================] - 537s 429ms/step - loss: 1.3684e-04 - correct_positive_diagnoses: 0.7006 - val_loss: 0.3027 - val_correct_positive_diagnoses: 0.0600\n",
      "\n",
      "Epoch 00019: saving model to weights/frozen_VGG_dense_head_new_windowing-epoch=19-valid-loss=0.30.hdf5\n",
      "Epoch 20/20\n",
      "1250/1250 [==============================] - 533s 426ms/step - loss: 0.0115 - correct_positive_diagnoses: 0.6565 - val_loss: 0.2614 - val_correct_positive_diagnoses: 0.1000\n",
      "\n",
      "Epoch 00020: saving model to weights/frozen_VGG_dense_head_new_windowing-epoch=20-valid-loss=0.26.hdf5\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit_generator(traingen,\n",
    "                    validation_data = validgen,\n",
    "                    epochs=20,\n",
    "                    verbose=True,\n",
    "                    use_multiprocessing=True,\n",
    "                    workers=4,\n",
    "                    callbacks=[mc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "Increasing input size results in slower learning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-brainenv",
   "language": "python",
   "name": "brainenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
